{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrvEUnBPB1Nqex+Am6u+oG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Teratoma111/amazon_review_analysis/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgFCT6RNysN4",
        "outputId": "db4aadf5-af12-4868-f551-f23b300f67d1"
      },
      "source": [
        "import torch\n",
        "from sklearn.model_selection import KFold\n",
        "from torchtext.legacy import data as data_leg\n",
        "from torchtext import data\n",
        "import numpy as np  \n",
        "import torch.optim as optim\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data_leg.Field(include_lengths = True,\n",
        "                  tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm')\n",
        "LABEL = data_leg.LabelField()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import random\n",
        "\n",
        "fields = {'reviewText': ('text', TEXT), 'overall': ('label', LABEL)}\n",
        "train_data= data_leg.TabularDataset.splits(\n",
        "                                        path = '/content/drive/MyDrive',\n",
        "                                        train = \"Musical_Instruments_5.json\",\n",
        "                                        format = 'json',\n",
        "                                        fields = fields)[0]\n",
        "for i in range(0, len(train_data)):\n",
        "  if(len(train_data[i].text) < 1):\n",
        "    train_data[i].text = train_data[3].text\n",
        "    train_data[i].label = train_data[3].label"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFW97-fAz7FF"
      },
      "source": [
        "def get_fold_data(train_data, num_folds=5):\n",
        "        \n",
        "        TEXT = data_leg.Field(include_lengths = True,\n",
        "                  tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm')\n",
        "        LABEL = data_leg.LabelField()\n",
        "        fields = [('text', TEXT), ('label', LABEL)]\n",
        "        \n",
        "        kf = KFold(n_splits=num_folds, shuffle=True, random_state = 42)\n",
        "        train_data_arr = np.array(train_data.examples)\n",
        "        for train_index, val_index in kf.split(train_data_arr):\n",
        "            yield(\n",
        "                TEXT,\n",
        "                LABEL,\n",
        "                data_leg.Dataset(train_data_arr[train_index], fields=fields),\n",
        "                data_leg.Dataset(train_data_arr[val_index], fields=fields),\n",
        "            )"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEGT4Wcr1MiW"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.rnn = nn.GRU(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n",
        "        \n",
        "        packed_output, hidden = self.rnn(packed_embedded)\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "\n",
        "        return self.fc(hidden)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G8h6aqF1MzQ"
      },
      "source": [
        "def get_weights(iterator):\n",
        "  weights = torch.zeros(len(LABEL.vocab))\n",
        "  for batch in iterator:\n",
        "    for i in batch.label:\n",
        "      weights[i.cpu().numpy()] +=1\n",
        "  for i in range(0, len(LABEL.vocab)):\n",
        "    weights[i] = (1 / weights[i]) * 100\n",
        "  return weights"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBSP_5tf1SR7"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "def categorical_accuracy(preds, y):\n",
        "    top_pred = preds.argmax(1, keepdim = True)\n",
        "    y_score = top_pred.detach().cpu().numpy()\n",
        "    y_true = y.view_as(top_pred).cpu().numpy()\n",
        "    f1 = f1_score(y_true, y_score, average = 'weighted')\n",
        "    rec = recall_score(y_true, y_score, average = 'weighted')\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return (rec, f1, acc)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX0TTKr81Trq"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_f1 = 0\n",
        "    epoch_rec = 0\n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        text, text_lengths = batch.text\n",
        "        \n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        metrics = categorical_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        acc = metrics[2]\n",
        "        f1 = metrics[1]\n",
        "        rec = metrics[0]\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        epoch_f1 += f1\n",
        "        epoch_rec += rec\n",
        "    epoch_acc /= len(iterator)\n",
        "    epoch_f1 /= len(iterator)\n",
        "    epoch_rec /= len(iterator)\n",
        "    return epoch_loss / len(iterator), (epoch_rec, epoch_f1, epoch_acc)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfR7QCnx1U_S"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_f1 = 0\n",
        "    epoch_rec = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text, text_lengths = batch.text\n",
        "            \n",
        "            predictions = model(text, text_lengths)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            metrics = categorical_accuracy(predictions, batch.label)\n",
        "\n",
        "            acc = metrics[2]\n",
        "            f1 = metrics[1]\n",
        "            rec = metrics[0]\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            epoch_f1 += f1\n",
        "            epoch_rec += rec\n",
        "        epoch_acc /= len(iterator)\n",
        "        epoch_f1 /= len(iterator)\n",
        "        epoch_rec /= len(iterator)\n",
        "        \n",
        "    return epoch_loss / len(iterator), (epoch_rec, epoch_f1, epoch_acc)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ3RjgSH1Wof"
      },
      "source": [
        "import time\n",
        "from torchtext import data, datasets\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G-p0Jyq0xtA",
        "outputId": "78e61b37-1248-4705-b118-0fa634249c55"
      },
      "source": [
        "fold_id = 0\n",
        "for TEXT, LABEL, train_data, val_data in get_fold_data(train_data):\n",
        "  print(f'Fold index: {fold_id}.')\n",
        "  fold_id +=1\n",
        "  TEXT.build_vocab(train_data, \n",
        "            vectors = \"fasttext.simple.300d\", \n",
        "            unk_init = torch.Tensor.normal_)\n",
        "  print(f'Embedding size: {TEXT.vocab.vectors.size()}.')\n",
        "  LABEL.build_vocab(train_data) \n",
        "  BATCH_SIZE = 128\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  train_iterator, valid_iterator = data_leg.BucketIterator.splits(\n",
        "      (train_data, val_data), \n",
        "      batch_size = BATCH_SIZE,\n",
        "      sort_key = lambda x: len(x.text),\n",
        "      #sort_within_batch = False,\n",
        "      sort_within_batch = True, \n",
        "      device = device)\n",
        "  \n",
        "  pretrained_embeddings = TEXT.vocab.vectors\n",
        "  INPUT_DIM = len(TEXT.vocab)\n",
        "  EMBEDDING_DIM = 300\n",
        "  HIDDEN_DIM = 512\n",
        "  OUTPUT_DIM = len(LABEL.vocab)\n",
        "  N_LAYERS = 4\n",
        "  BIDIRECTIONAL = True\n",
        "  DROPOUT = 0.6\n",
        "  PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "  model = RNN(INPUT_DIM, \n",
        "              EMBEDDING_DIM, \n",
        "              HIDDEN_DIM, \n",
        "              OUTPUT_DIM, \n",
        "              N_LAYERS, \n",
        "              BIDIRECTIONAL, \n",
        "              DROPOUT, \n",
        "              PAD_IDX)\n",
        "  model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "  UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "  model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "  model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss(weight =  get_weights(train_iterator))\n",
        "\n",
        "  model = model.to(device)\n",
        "  criterion = criterion.to(device)\n",
        "  N_EPOCHS = 20\n",
        "\n",
        "  best_valid_score = float('0')\n",
        "  best_f1 = float('0')\n",
        "  for epoch in range(N_EPOCHS):\n",
        "\n",
        "      start_time = time.time()\n",
        "      train_res = train(model, train_iterator, optimizer, criterion)\n",
        "      train_loss = train_res[0]\n",
        "      train_score = train_res[1]\n",
        "      valid_res = evaluate(model, valid_iterator, criterion)\n",
        "      valid_score = valid_res[1]\n",
        "      valid_loss = valid_res[0]\n",
        "      end_time = time.time()\n",
        "      valid_acc = (valid_score[1])\n",
        "      acc = valid_acc\n",
        "      #print(float(valid_acc))\n",
        "      epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "      print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "      if acc > best_valid_score:\n",
        "          best_valid_score= acc\n",
        "          best_f1 = valid_score[1]*100\n",
        "          torch.save(model.state_dict(), '/content/drive/MyDrive/mo1.pt')\n",
        "          print(f'\\tValid Loss: {valid_loss:.3f} | Valid F1: {valid_score[1]*100:.2f}% | Valid rec: {valid_score[0]*100:.2f}% | Valid acc: {valid_score[2]*100:.2f}%')\n",
        "      print(f'\\tTrain Loss: {train_loss:.3f} | Train F1: {train_score[1]*100:.2f}% | Train rec: {train_score[0]*100:.2f}% | Train acc: {train_score[2]*100:.2f}%')\n",
        "  print(\"--------------------------------\")\n",
        "  print(best_valid_score, best_f1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold index: 0.\n",
            "Embedding size: torch.Size([25827, 300]).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 32s\n",
            "\tValid Loss: 1.632 | Valid F1: 8.58% | Valid rec: 7.81% | Valid acc: 7.81%\n",
            "\tTrain Loss: 1.661 | Train F1: 28.11% | Train rec: 26.20% | Train acc: 26.20%\n",
            "Epoch: 02 | Epoch Time: 0m 33s\n",
            "\tValid Loss: 1.592 | Valid F1: 58.02% | Valid rec: 57.80% | Valid acc: 57.80%\n",
            "\tTrain Loss: 1.631 | Train F1: 32.61% | Train rec: 28.15% | Train acc: 28.15%\n",
            "Epoch: 03 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.583 | Train F1: 39.05% | Train rec: 33.74% | Train acc: 33.74%\n",
            "Epoch: 04 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 1.575 | Train F1: 39.63% | Train rec: 35.07% | Train acc: 35.07%\n",
            "Epoch: 05 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 1.475 | Train F1: 41.52% | Train rec: 37.39% | Train acc: 37.39%\n",
            "Epoch: 06 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.354 | Train F1: 45.11% | Train rec: 41.08% | Train acc: 41.08%\n",
            "Epoch: 07 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.287 | Train F1: 47.27% | Train rec: 43.70% | Train acc: 43.70%\n",
            "Epoch: 08 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.188 | Train F1: 48.37% | Train rec: 44.87% | Train acc: 44.87%\n",
            "Epoch: 09 | Epoch Time: 0m 34s\n",
            "\tValid Loss: 2.044 | Valid F1: 59.18% | Valid rec: 58.63% | Valid acc: 58.63%\n",
            "\tTrain Loss: 1.146 | Train F1: 46.76% | Train rec: 44.57% | Train acc: 44.57%\n",
            "Epoch: 10 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.027 | Train F1: 52.15% | Train rec: 48.87% | Train acc: 48.87%\n",
            "Epoch: 11 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.919 | Train F1: 54.77% | Train rec: 52.22% | Train acc: 52.22%\n",
            "Epoch: 12 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.931 | Train F1: 55.75% | Train rec: 52.90% | Train acc: 52.90%\n",
            "Epoch: 13 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.850 | Train F1: 56.29% | Train rec: 53.69% | Train acc: 53.69%\n",
            "Epoch: 14 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.801 | Train F1: 58.87% | Train rec: 56.94% | Train acc: 56.94%\n",
            "Epoch: 15 | Epoch Time: 0m 34s\n",
            "\tValid Loss: 2.451 | Valid F1: 60.56% | Valid rec: 62.31% | Valid acc: 62.31%\n",
            "\tTrain Loss: 0.725 | Train F1: 61.30% | Train rec: 58.58% | Train acc: 58.58%\n",
            "Epoch: 16 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.670 | Train F1: 62.03% | Train rec: 59.78% | Train acc: 59.78%\n",
            "Epoch: 17 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.610 | Train F1: 64.85% | Train rec: 62.76% | Train acc: 62.76%\n",
            "Epoch: 18 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.600 | Train F1: 64.05% | Train rec: 62.28% | Train acc: 62.28%\n",
            "Epoch: 19 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.600 | Train F1: 64.44% | Train rec: 62.51% | Train acc: 62.51%\n",
            "Epoch: 20 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.516 | Train F1: 67.76% | Train rec: 66.18% | Train acc: 66.18%\n",
            "--------------------------------\n",
            "0.6056040240072587 60.56040240072586\n",
            "Fold index: 1.\n",
            "Embedding size: torch.Size([26125, 300]).\n",
            "Epoch: 01 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 1.695 | Valid F1: 25.66% | Valid rec: 19.07% | Valid acc: 19.07%\n",
            "\tTrain Loss: 1.663 | Train F1: 27.61% | Train rec: 25.17% | Train acc: 25.17%\n",
            "Epoch: 02 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 1.640 | Valid F1: 44.13% | Valid rec: 39.94% | Valid acc: 39.94%\n",
            "\tTrain Loss: 1.634 | Train F1: 33.64% | Train rec: 28.97% | Train acc: 28.97%\n",
            "Epoch: 03 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.594 | Train F1: 38.79% | Train rec: 33.88% | Train acc: 33.88%\n",
            "Epoch: 04 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 1.674 | Valid F1: 46.75% | Valid rec: 42.88% | Valid acc: 42.88%\n",
            "\tTrain Loss: 1.538 | Train F1: 39.30% | Train rec: 35.10% | Train acc: 35.10%\n",
            "Epoch: 05 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.466 | Train F1: 41.16% | Train rec: 37.39% | Train acc: 37.39%\n",
            "Epoch: 06 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 1.868 | Valid F1: 53.29% | Valid rec: 50.18% | Valid acc: 50.18%\n",
            "\tTrain Loss: 1.328 | Train F1: 43.05% | Train rec: 39.08% | Train acc: 39.08%\n",
            "Epoch: 07 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.300 | Train F1: 48.83% | Train rec: 44.61% | Train acc: 44.61%\n",
            "Epoch: 08 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 1.606 | Valid F1: 57.05% | Valid rec: 58.00% | Valid acc: 58.00%\n",
            "\tTrain Loss: 1.166 | Train F1: 47.74% | Train rec: 43.59% | Train acc: 43.59%\n",
            "Epoch: 09 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.076 | Train F1: 50.48% | Train rec: 48.06% | Train acc: 48.06%\n",
            "Epoch: 10 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 2.153 | Valid F1: 57.51% | Valid rec: 63.74% | Valid acc: 63.74%\n",
            "\tTrain Loss: 1.039 | Train F1: 51.77% | Train rec: 48.77% | Train acc: 48.77%\n",
            "Epoch: 11 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.953 | Train F1: 53.62% | Train rec: 51.81% | Train acc: 51.81%\n",
            "Epoch: 12 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.879 | Train F1: 56.34% | Train rec: 53.19% | Train acc: 53.19%\n",
            "Epoch: 13 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.796 | Train F1: 60.21% | Train rec: 57.53% | Train acc: 57.53%\n",
            "Epoch: 14 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.785 | Train F1: 58.71% | Train rec: 56.24% | Train acc: 56.24%\n",
            "Epoch: 15 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 2.670 | Valid F1: 59.26% | Valid rec: 58.13% | Valid acc: 58.13%\n",
            "\tTrain Loss: 0.717 | Train F1: 61.71% | Train rec: 59.34% | Train acc: 59.34%\n",
            "Epoch: 16 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.681 | Train F1: 62.06% | Train rec: 59.91% | Train acc: 59.91%\n",
            "Epoch: 17 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.622 | Train F1: 63.69% | Train rec: 61.55% | Train acc: 61.55%\n",
            "Epoch: 18 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.605 | Train F1: 65.57% | Train rec: 63.65% | Train acc: 63.65%\n",
            "Epoch: 19 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.540 | Train F1: 68.67% | Train rec: 66.64% | Train acc: 66.64%\n",
            "Epoch: 20 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.549 | Train F1: 68.57% | Train rec: 66.49% | Train acc: 66.49%\n",
            "--------------------------------\n",
            "0.5925703119221141 59.25703119221141\n",
            "Fold index: 2.\n",
            "Embedding size: torch.Size([26104, 300]).\n",
            "Epoch: 01 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 1.656 | Valid F1: 29.77% | Valid rec: 22.33% | Valid acc: 22.33%\n",
            "\tTrain Loss: 1.647 | Train F1: 29.07% | Train rec: 26.79% | Train acc: 26.79%\n",
            "Epoch: 02 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 1.622 | Valid F1: 42.75% | Valid rec: 35.06% | Valid acc: 35.06%\n",
            "\tTrain Loss: 1.616 | Train F1: 33.45% | Train rec: 28.10% | Train acc: 28.10%\n",
            "Epoch: 03 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.608 | Train F1: 36.06% | Train rec: 31.80% | Train acc: 31.80%\n",
            "Epoch: 04 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.523 | Train F1: 40.52% | Train rec: 35.75% | Train acc: 35.75%\n",
            "Epoch: 05 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.442 | Train F1: 44.46% | Train rec: 39.52% | Train acc: 39.52%\n",
            "Epoch: 06 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 1.932 | Valid F1: 58.77% | Valid rec: 58.64% | Valid acc: 58.64%\n",
            "\tTrain Loss: 1.359 | Train F1: 44.37% | Train rec: 39.75% | Train acc: 39.75%\n",
            "Epoch: 07 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.226 | Train F1: 49.20% | Train rec: 45.32% | Train acc: 45.32%\n",
            "Epoch: 08 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 2.237 | Valid F1: 59.53% | Valid rec: 60.52% | Valid acc: 60.52%\n",
            "\tTrain Loss: 1.150 | Train F1: 50.08% | Train rec: 46.97% | Train acc: 46.97%\n",
            "Epoch: 09 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.001 | Train F1: 54.13% | Train rec: 50.58% | Train acc: 50.58%\n",
            "Epoch: 10 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.913 | Train F1: 54.20% | Train rec: 51.85% | Train acc: 51.85%\n",
            "Epoch: 11 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 2.500 | Valid F1: 61.33% | Valid rec: 60.71% | Valid acc: 60.71%\n",
            "\tTrain Loss: 0.841 | Train F1: 57.74% | Train rec: 55.36% | Train acc: 55.36%\n",
            "Epoch: 12 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.820 | Train F1: 61.08% | Train rec: 58.54% | Train acc: 58.54%\n",
            "Epoch: 13 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.767 | Train F1: 60.38% | Train rec: 58.22% | Train acc: 58.22%\n",
            "Epoch: 14 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.727 | Train F1: 57.83% | Train rec: 56.93% | Train acc: 56.93%\n",
            "Epoch: 15 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 3.015 | Valid F1: 61.41% | Valid rec: 59.65% | Valid acc: 59.65%\n",
            "\tTrain Loss: 0.650 | Train F1: 64.78% | Train rec: 62.67% | Train acc: 62.67%\n",
            "Epoch: 16 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.614 | Train F1: 66.58% | Train rec: 64.50% | Train acc: 64.50%\n",
            "Epoch: 17 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.602 | Train F1: 65.10% | Train rec: 63.52% | Train acc: 63.52%\n",
            "Epoch: 18 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.556 | Train F1: 67.51% | Train rec: 65.55% | Train acc: 65.55%\n",
            "Epoch: 19 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.588 | Train F1: 66.49% | Train rec: 64.77% | Train acc: 64.77%\n",
            "Epoch: 20 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.542 | Train F1: 68.85% | Train rec: 67.02% | Train acc: 67.02%\n",
            "--------------------------------\n",
            "0.6141371643562339 61.413716435623385\n",
            "Fold index: 3.\n",
            "Embedding size: torch.Size([25915, 300]).\n",
            "Epoch: 01 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 1.629 | Valid F1: 39.83% | Valid rec: 32.35% | Valid acc: 32.35%\n",
            "\tTrain Loss: 1.655 | Train F1: 28.48% | Train rec: 25.91% | Train acc: 25.91%\n",
            "Epoch: 02 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 1.604 | Valid F1: 55.25% | Valid rec: 52.85% | Valid acc: 52.85%\n",
            "\tTrain Loss: 1.637 | Train F1: 33.87% | Train rec: 29.14% | Train acc: 29.14%\n",
            "Epoch: 03 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.586 | Train F1: 38.35% | Train rec: 32.87% | Train acc: 32.87%\n",
            "Epoch: 04 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.528 | Train F1: 42.06% | Train rec: 37.15% | Train acc: 37.15%\n",
            "Epoch: 05 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.475 | Train F1: 42.53% | Train rec: 37.91% | Train acc: 37.91%\n",
            "Epoch: 06 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 2.098 | Valid F1: 56.84% | Valid rec: 58.96% | Valid acc: 58.96%\n",
            "\tTrain Loss: 1.377 | Train F1: 45.42% | Train rec: 40.89% | Train acc: 40.89%\n",
            "Epoch: 07 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.263 | Train F1: 49.58% | Train rec: 45.98% | Train acc: 45.98%\n",
            "Epoch: 08 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 1.943 | Valid F1: 57.02% | Valid rec: 54.41% | Valid acc: 54.41%\n",
            "\tTrain Loss: 1.122 | Train F1: 48.96% | Train rec: 45.59% | Train acc: 45.59%\n",
            "Epoch: 09 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.063 | Train F1: 54.00% | Train rec: 50.84% | Train acc: 50.84%\n",
            "Epoch: 10 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.910 | Train F1: 57.22% | Train rec: 54.05% | Train acc: 54.05%\n",
            "Epoch: 11 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 2.608 | Valid F1: 57.11% | Valid rec: 54.09% | Valid acc: 54.09%\n",
            "\tTrain Loss: 0.907 | Train F1: 56.08% | Train rec: 53.34% | Train acc: 53.34%\n",
            "Epoch: 12 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.809 | Train F1: 58.70% | Train rec: 56.26% | Train acc: 56.26%\n",
            "Epoch: 13 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 2.877 | Valid F1: 62.50% | Valid rec: 64.11% | Valid acc: 64.11%\n",
            "\tTrain Loss: 0.850 | Train F1: 57.56% | Train rec: 55.45% | Train acc: 55.45%\n",
            "Epoch: 14 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.795 | Train F1: 58.49% | Train rec: 56.66% | Train acc: 56.66%\n",
            "Epoch: 15 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.693 | Train F1: 62.67% | Train rec: 60.11% | Train acc: 60.11%\n",
            "Epoch: 16 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.636 | Train F1: 65.59% | Train rec: 63.33% | Train acc: 63.33%\n",
            "Epoch: 17 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.643 | Train F1: 64.01% | Train rec: 62.04% | Train acc: 62.04%\n",
            "Epoch: 18 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.634 | Train F1: 64.03% | Train rec: 62.09% | Train acc: 62.09%\n",
            "Epoch: 19 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.527 | Train F1: 68.57% | Train rec: 66.90% | Train acc: 66.90%\n",
            "Epoch: 20 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.516 | Train F1: 66.44% | Train rec: 65.21% | Train acc: 65.21%\n",
            "--------------------------------\n",
            "0.625038145842689 62.5038145842689\n",
            "Fold index: 4.\n",
            "Embedding size: torch.Size([25912, 300]).\n",
            "Epoch: 01 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 1.691 | Valid F1: 26.62% | Valid rec: 19.99% | Valid acc: 19.99%\n",
            "\tTrain Loss: 1.648 | Train F1: 28.01% | Train rec: 26.65% | Train acc: 26.65%\n",
            "Epoch: 02 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 1.653 | Valid F1: 30.59% | Valid rec: 24.26% | Valid acc: 24.26%\n",
            "\tTrain Loss: 1.618 | Train F1: 34.46% | Train rec: 30.51% | Train acc: 30.51%\n",
            "Epoch: 03 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.572 | Train F1: 38.13% | Train rec: 33.16% | Train acc: 33.16%\n",
            "Epoch: 04 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 1.761 | Valid F1: 38.09% | Valid rec: 33.96% | Valid acc: 33.96%\n",
            "\tTrain Loss: 1.540 | Train F1: 41.33% | Train rec: 36.39% | Train acc: 36.39%\n",
            "Epoch: 05 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.420 | Train F1: 41.21% | Train rec: 36.83% | Train acc: 36.83%\n",
            "Epoch: 06 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 2.216 | Valid F1: 58.58% | Valid rec: 57.54% | Valid acc: 57.54%\n",
            "\tTrain Loss: 1.344 | Train F1: 45.72% | Train rec: 41.45% | Train acc: 41.45%\n",
            "Epoch: 07 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.266 | Train F1: 49.87% | Train rec: 45.83% | Train acc: 45.83%\n",
            "Epoch: 08 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.124 | Train F1: 50.70% | Train rec: 47.32% | Train acc: 47.32%\n",
            "Epoch: 09 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 1.061 | Train F1: 52.93% | Train rec: 49.67% | Train acc: 49.67%\n",
            "Epoch: 10 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.963 | Train F1: 56.19% | Train rec: 52.96% | Train acc: 52.96%\n",
            "Epoch: 11 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.941 | Train F1: 54.67% | Train rec: 52.61% | Train acc: 52.61%\n",
            "Epoch: 12 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.815 | Train F1: 58.62% | Train rec: 55.86% | Train acc: 55.86%\n",
            "Epoch: 13 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 3.156 | Valid F1: 59.94% | Valid rec: 65.03% | Valid acc: 65.03%\n",
            "\tTrain Loss: 0.744 | Train F1: 58.44% | Train rec: 56.43% | Train acc: 56.43%\n",
            "Epoch: 14 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.731 | Train F1: 60.46% | Train rec: 58.63% | Train acc: 58.63%\n",
            "Epoch: 15 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.668 | Train F1: 63.70% | Train rec: 61.64% | Train acc: 61.64%\n",
            "Epoch: 16 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.705 | Train F1: 62.56% | Train rec: 60.25% | Train acc: 60.25%\n",
            "Epoch: 17 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.627 | Train F1: 63.55% | Train rec: 62.26% | Train acc: 62.26%\n",
            "Epoch: 18 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.595 | Train F1: 65.03% | Train rec: 63.18% | Train acc: 63.18%\n",
            "Epoch: 19 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.517 | Train F1: 69.46% | Train rec: 67.74% | Train acc: 67.74%\n",
            "Epoch: 20 | Epoch Time: 0m 35s\n",
            "\tValid Loss: 3.602 | Valid F1: 61.25% | Valid rec: 59.65% | Valid acc: 59.65%\n",
            "\tTrain Loss: 0.504 | Train F1: 70.62% | Train rec: 68.86% | Train acc: 68.86%\n",
            "--------------------------------\n",
            "0.6125011146120236 61.25011146120236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "OqBRpIoi792Q",
        "outputId": "dbb030ce-e93d-480d-b394-eff0a67f7217"
      },
      "source": [
        "\n",
        "n_categories = len(LABEL.vocab)\n",
        "confusion = np.zeros((n_categories, n_categories))\n",
        "\n",
        "model.eval()\n",
        "sum = 0\n",
        "with torch.no_grad():\n",
        "    for batch in train_iterator:\n",
        "      text, text_lengths = batch.text\n",
        "      predictions = model(text, text_lengths).squeeze(1)\n",
        "      y = batch.label\n",
        "      top_pred = predictions.argmax(1, keepdim = True)\n",
        "      y_score = top_pred.detach().cpu().numpy()\n",
        "      y_true = y.view_as(top_pred).cpu().numpy()\n",
        "      for i in range(0, y_true.shape[0]):\n",
        "        confusion[[y_true[i] , y_score[i]]] +=1\n",
        "\n",
        "for i in range(n_categories):\n",
        "    confusion[i] = confusion[i] / confusion[i].sum()\n",
        "  \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(confusion)\n",
        "fig.colorbar(cax)\n",
        "all_categories = [1, 2, 3 ,4 ,5]\n",
        "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
        "ax.set_yticklabels([''] + all_categories)\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "O9w5pojSFzMj",
        "outputId": "b9d6b82c-0b84-4a65-c4e7-0acc76fa0d9d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(confusion)\n",
        "fig.colorbar(cax)\n",
        "all_categories = [1, 2, 3 ,4 ,5]\n",
        "ax.set_xticklabels([''] + all_categories)\n",
        "ax.set_yticklabels([''] + all_categories)\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
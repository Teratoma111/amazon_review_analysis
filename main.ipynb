{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOyAZiB4JPFOQNU1iTBKg/0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Teratoma111/amazon_review_analysis/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgFCT6RNysN4",
        "outputId": "8e89924b-a495-4b9b-ce81-b187a921c71d"
      },
      "source": [
        "import torch\n",
        "from sklearn.model_selection import KFold\n",
        "from torchtext.legacy import data as data_leg\n",
        "from torchtext import data\n",
        "import numpy as np  \n",
        "import torch.optim as optim\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data_leg.Field(include_lengths = True,\n",
        "                  tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm')\n",
        "LABEL = data_leg.LabelField()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import random\n",
        "\n",
        "fields = {'reviewText': ('text', TEXT), 'overall': ('label', LABEL)}\n",
        "train_data= data_leg.TabularDataset.splits(\n",
        "                                        path = '/content/drive/MyDrive',\n",
        "                                        train = \"Musical_Instruments_5.json\",\n",
        "                                        format = 'json',\n",
        "                                        fields = fields)[0]\n",
        "for i in range(0, len(train_data)):\n",
        "  if(len(train_data[i].text) < 1):\n",
        "    train_data[i].text = train_data[3].text\n",
        "    train_data[i].label = train_data[3].label"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFW97-fAz7FF"
      },
      "source": [
        "def get_fold_data(train_data, num_folds=5):\n",
        "        \n",
        "        TEXT = data_leg.Field(include_lengths = True,\n",
        "                  tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm')\n",
        "        LABEL = data_leg.LabelField()\n",
        "        fields = [('text', TEXT), ('label', LABEL)]\n",
        "        \n",
        "        kf = KFold(n_splits=num_folds, shuffle=True, random_state = 42)\n",
        "        train_data_arr = np.array(train_data.examples)\n",
        "        for train_index, val_index in kf.split(train_data_arr):\n",
        "            yield(\n",
        "                TEXT,\n",
        "                LABEL,\n",
        "                data_leg.Dataset(train_data_arr[train_index], fields=fields),\n",
        "                data_leg.Dataset(train_data_arr[val_index], fields=fields),\n",
        "            )"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEGT4Wcr1MiW"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.rnn = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "\n",
        "        return self.fc(hidden)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G8h6aqF1MzQ"
      },
      "source": [
        "def get_weights(iterator):\n",
        "  weights = torch.zeros(len(LABEL.vocab))\n",
        "  for batch in iterator:\n",
        "    for i in batch.label:\n",
        "      weights[i.cpu().numpy()] +=1\n",
        "  for i in range(0, len(LABEL.vocab)):\n",
        "    weights[i] = (1 / weights[i]) * 100\n",
        "  return weights"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBSP_5tf1SR7"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "def categorical_accuracy(preds, y):\n",
        "    top_pred = preds.argmax(1, keepdim = True)\n",
        "    y_score = top_pred.detach().cpu().numpy()\n",
        "    y_true = y.view_as(top_pred).cpu().numpy()\n",
        "    f1 = f1_score(y_true, y_score, average = 'weighted')\n",
        "    rec = recall_score(y_true, y_score, average = 'weighted')\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return (rec, f1, acc)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX0TTKr81Trq"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_f1 = 0\n",
        "    epoch_rec = 0\n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        text, text_lengths = batch.text\n",
        "        \n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        metrics = categorical_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        acc = metrics[2]\n",
        "        f1 = metrics[1]\n",
        "        rec = metrics[0]\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        epoch_f1 += f1\n",
        "        epoch_rec += rec\n",
        "    epoch_acc /= len(iterator)\n",
        "    epoch_f1 /= len(iterator)\n",
        "    epoch_rec /= len(iterator)\n",
        "    return epoch_loss / len(iterator), (epoch_rec, epoch_f1, epoch_acc)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfR7QCnx1U_S"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_f1 = 0\n",
        "    epoch_rec = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text, text_lengths = batch.text\n",
        "            \n",
        "            predictions = model(text, text_lengths)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            metrics = categorical_accuracy(predictions, batch.label)\n",
        "\n",
        "            acc = metrics[2]\n",
        "            f1 = metrics[1]\n",
        "            rec = metrics[0]\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            epoch_f1 += f1\n",
        "            epoch_rec += rec\n",
        "        epoch_acc /= len(iterator)\n",
        "        epoch_f1 /= len(iterator)\n",
        "        epoch_rec /= len(iterator)\n",
        "        \n",
        "    return epoch_loss / len(iterator), (epoch_rec, epoch_f1, epoch_acc)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ3RjgSH1Wof"
      },
      "source": [
        "import time\n",
        "from torchtext import data, datasets\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "6G-p0Jyq0xtA",
        "outputId": "d9fdf996-f5b1-4497-f500-43e660614b33"
      },
      "source": [
        "fold_id = 0\n",
        "for TEXT, LABEL, train_data, val_data in get_fold_data(train_data):\n",
        "  print(f'Fold index: {fold_id}.')\n",
        "  fold_id +=1\n",
        "  TEXT.build_vocab(train_data, \n",
        "            vectors = \"fasttext.simple.300d\", \n",
        "            unk_init = torch.Tensor.normal_)\n",
        "  print(f'Embedding size: {TEXT.vocab.vectors.size()}.')\n",
        "  LABEL.build_vocab(train_data) \n",
        "  BATCH_SIZE = 64\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  train_iterator, valid_iterator = data_leg.BucketIterator.splits(\n",
        "      (train_data, val_data), \n",
        "      batch_size = BATCH_SIZE,\n",
        "      sort_key = lambda x: len(x.text),\n",
        "      #sort_within_batch = False,\n",
        "      sort_within_batch = True, \n",
        "      device = device)\n",
        "  \n",
        "  pretrained_embeddings = TEXT.vocab.vectors\n",
        "  INPUT_DIM = len(TEXT.vocab)\n",
        "  EMBEDDING_DIM = 300\n",
        "  HIDDEN_DIM = 512\n",
        "  OUTPUT_DIM = len(LABEL.vocab)\n",
        "  N_LAYERS = 4\n",
        "  BIDIRECTIONAL = True\n",
        "  DROPOUT = 0.5\n",
        "  PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "  model = RNN(INPUT_DIM, \n",
        "              EMBEDDING_DIM, \n",
        "              HIDDEN_DIM, \n",
        "              OUTPUT_DIM, \n",
        "              N_LAYERS, \n",
        "              BIDIRECTIONAL, \n",
        "              DROPOUT, \n",
        "              PAD_IDX)\n",
        "  model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "  UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "  model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "  model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss(weight =  get_weights(train_iterator))\n",
        "\n",
        "  model = model.to(device)\n",
        "  criterion = criterion.to(device)\n",
        "  N_EPOCHS = 10\n",
        "\n",
        "  best_valid_score = float('0')\n",
        "\n",
        "  for epoch in range(N_EPOCHS):\n",
        "\n",
        "      start_time = time.time()\n",
        "      train_res = train(model, train_iterator, optimizer, criterion)\n",
        "      train_loss = train_res[0]\n",
        "      train_score = train_res[1]\n",
        "      valid_res = evaluate(model, valid_iterator, criterion)\n",
        "      valid_score = valid_res[1]\n",
        "      valid_loss = valid_res[0]\n",
        "      end_time = time.time()\n",
        "      valid_acc = (valid_score[1])\n",
        "      acc = valid_acc\n",
        "      #print(float(valid_acc))\n",
        "      epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "      print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "      if acc > best_valid_score:\n",
        "          best_valid_score= acc\n",
        "          torch.save(model.state_dict(), '/content/drive/MyDrive/mo1.pt')\n",
        "          print(f'\\tValid Loss: {valid_loss:.3f} | Valid F1: {valid_score[1]*100:.2f}% | Valid rec: {valid_score[0]*100:.2f}% | Valid acc: {valid_score[2]*100:.2f}%')\n",
        "      print(f'\\tTrain Loss: {train_loss:.3f} | Train F1: {train_score[1]*100:.2f}% | Train rec: {train_score[0]*100:.2f}% | Train acc: {train_score[2]*100:.2f}%')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold index: 0.\n",
            "Embedding size: torch.Size([25827, 300]).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 42s\n",
            "\tValid Loss: 1.604 | Valid F1: 50.50% | Valid rec: 49.59% | Valid acc: 49.59%\n",
            "\tTrain Loss: 1.618 | Train F1: 27.99% | Train rec: 28.92% | Train acc: 28.92%\n",
            "Epoch: 02 | Epoch Time: 1m 44s\n",
            "\tValid Loss: 1.602 | Valid F1: 57.32% | Valid rec: 62.94% | Valid acc: 62.94%\n",
            "\tTrain Loss: 1.590 | Train F1: 40.53% | Train rec: 37.86% | Train acc: 37.86%\n",
            "Epoch: 03 | Epoch Time: 1m 44s\n",
            "\tTrain Loss: 1.513 | Train F1: 42.05% | Train rec: 37.60% | Train acc: 37.60%\n",
            "Epoch: 04 | Epoch Time: 1m 45s\n",
            "\tTrain Loss: 1.390 | Train F1: 45.94% | Train rec: 41.72% | Train acc: 41.72%\n",
            "Epoch: 05 | Epoch Time: 1m 45s\n",
            "\tTrain Loss: 1.268 | Train F1: 46.30% | Train rec: 41.91% | Train acc: 41.91%\n",
            "Epoch: 06 | Epoch Time: 1m 45s\n",
            "\tValid Loss: 1.903 | Valid F1: 58.83% | Valid rec: 60.10% | Valid acc: 60.10%\n",
            "\tTrain Loss: 1.185 | Train F1: 48.31% | Train rec: 45.13% | Train acc: 45.13%\n",
            "Epoch: 07 | Epoch Time: 1m 44s\n",
            "\tTrain Loss: 0.987 | Train F1: 54.44% | Train rec: 50.98% | Train acc: 50.98%\n",
            "Epoch: 08 | Epoch Time: 1m 45s\n",
            "\tTrain Loss: 0.920 | Train F1: 53.87% | Train rec: 51.47% | Train acc: 51.47%\n",
            "Epoch: 09 | Epoch Time: 1m 44s\n",
            "\tValid Loss: 2.085 | Valid F1: 59.55% | Valid rec: 60.63% | Valid acc: 60.63%\n",
            "\tTrain Loss: 0.805 | Train F1: 58.30% | Train rec: 55.28% | Train acc: 55.28%\n",
            "Epoch: 10 | Epoch Time: 1m 45s\n",
            "\tTrain Loss: 0.710 | Train F1: 59.04% | Train rec: 56.70% | Train acc: 56.70%\n",
            "Fold index: 1.\n",
            "Embedding size: torch.Size([26125, 300]).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-5e0d2a2b4260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m       \u001b[0mtrain_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-aa8caae11dba>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorical_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "OqBRpIoi792Q",
        "outputId": "4b1b023d-d96f-4c99-ebd6-a11095268141"
      },
      "source": [
        "\n",
        "n_categories = len(LABEL.vocab)\n",
        "confusion = np.zeros((n_categories, n_categories))\n",
        "\n",
        "model.eval()\n",
        "sum = 0\n",
        "with torch.no_grad():\n",
        "    for batch in train_iterator:\n",
        "      text, text_lengths = batch.text\n",
        "      predictions = model(text, text_lengths).squeeze(1)\n",
        "      y = batch.label\n",
        "      top_pred = predictions.argmax(1, keepdim = True)\n",
        "      y_score = top_pred.detach().cpu().numpy()\n",
        "      y_true = y.view_as(top_pred).cpu().numpy()\n",
        "      for i in range(0, y_true.shape[0]):\n",
        "        confusion[[y_true[i] , y_score[i]]] +=1\n",
        "\n",
        "for i in range(n_categories):\n",
        "    confusion[i] = confusion[i] / confusion[i].sum()\n",
        "  \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(confusion)\n",
        "fig.colorbar(cax)\n",
        "all_categories = [1, 2, 3 ,4 ,5]\n",
        "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
        "ax.set_yticklabels([''] + all_categories)\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "O9w5pojSFzMj",
        "outputId": "6beda5a9-002d-4429-a604-337ed7cd3742"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(confusion)\n",
        "fig.colorbar(cax)\n",
        "all_categories = [1, 2, 3 ,4 ,5]\n",
        "ax.set_xticklabels([''] + all_categories)\n",
        "ax.set_yticklabels([''] + all_categories)\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}